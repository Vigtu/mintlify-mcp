<p align="center">
  <a href="https://github.com/Vigtu/docmole">
    <img loading="lazy" alt="docmole" src="https://raw.githubusercontent.com/Vigtu/docmole/main/assets/docmole-hero.svg" width="100%"/>
  </a>
</p>

# Docmole

<p align="center">
  <em>Dig through any documentation with AI</em>
</p>

[![npm version](https://img.shields.io/npm/v/docmole.svg)](https://www.npmjs.com/package/docmole)
[![License MIT](https://img.shields.io/github/license/Vigtu/docmole)](https://opensource.org/licenses/MIT)
[![Bun](https://img.shields.io/badge/runtime-Bun-f9f1e1?logo=bun)](https://bun.sh)
[![MCP](https://img.shields.io/badge/protocol-MCP-blue)](https://modelcontextprotocol.io)

Docmole is an MCP server that lets you query **any documentation site** from AI assistants like Claude, Cursor, or any MCP-compatible client. The mole digs through docs so you don't have to.

## Features

* ğŸ” **Universal docs support** â€” works with any documentation site
* ğŸ  **Self-hosted RAG** â€” LanceDB vectors + OpenAI embeddings, no Python needed
* âš¡ **Zero-setup mode** â€” instant access to Mintlify-powered sites
* ğŸ§  **Multi-turn conversations** â€” remembers context across questions
* ğŸ”— **WebFetch compatible** â€” links converted to absolute URLs
* ğŸ”Œ **MCP native** â€” works with Claude, Cursor, and any MCP client

### Coming soon

* ğŸ¦™ **Ollama support** â€” fully local mode, no API keys needed
* ğŸ“„ **Generic HTML extraction** â€” support for non-Mintlify documentation sites
* ğŸ”„ **Incremental updates** â€” only re-index changed pages

## Installation

To use Docmole, run it directly with bunx (no install needed):

```bash
bunx docmole --help
```

Or install globally:

```bash
bun install -g docmole
```

Works on macOS, Linux and Windows. Requires [Bun](https://bun.sh) runtime.

## Getting started

### Local RAG Mode (any docs site)

Index and query any documentation site. Requires `OPENAI_API_KEY`.

```bash
# One-time setup â€” discovers pages and builds vector index
bunx docmole setup --url https://docs.example.com --id my-docs

# Start the MCP server
bunx docmole serve --project my-docs
```

Add to your MCP client:

```json
{
  "mcpServers": {
    "my-docs": {
      "command": "bunx",
      "args": ["docmole", "serve", "--project", "my-docs"]
    }
  }
}
```

### Mintlify Mode (zero setup)

For sites with [Mintlify AI Assistant](https://mintlify.com) â€” no API key needed:

```bash
bunx docmole -p agno-v2
```

```json
{
  "mcpServers": {
    "agno-docs": {
      "command": "bunx",
      "args": ["docmole", "-p", "agno-v2"]
    }
  }
}
```

## CLI

Docmole has a built-in CLI for all operations:

```bash
# Mintlify mode (proxy to Mintlify API)
docmole -p <project-id>

# Local RAG mode
docmole setup --url <docs-url> --id <project-id>
docmole serve --project <project-id>
docmole list
docmole stop --project <project-id>
```

Run `docmole --help` for all options.

## How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP Client  â”‚â”€â”€â”€â”€â–¶â”‚   Docmole   â”‚â”€â”€â”€â”€â–¶â”‚ Embedded: LanceDB    â”‚
â”‚ (Claude,    â”‚â—€â”€â”€â”€â”€â”‚ MCP Server  â”‚â—€â”€â”€â”€â”€â”‚ Mintlify: API proxy  â”‚
â”‚  Cursor...) â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Local RAG Mode**: Crawls documentation, generates embeddings with OpenAI, stores in LanceDB. Hybrid search combines semantic and keyword matching.

**Mintlify Mode**: Proxies requests to Mintlify's AI Assistant API. Zero setup, instant results.

## Known Mintlify Project IDs

| Documentation | Project ID |
|--------------|------------|
| [Agno](https://docs.agno.com) | `agno-v2` |
| [Resend](https://resend.com/docs) | `resend` |
| [Mintlify](https://mintlify.com/docs) | `mintlify` |
| [Vercel](https://vercel.com/docs) | `vercel` |
| [Upstash](https://upstash.com/docs) | `upstash` |
| [Plain](https://plain.com/docs) | `plain` |

> **Find more**: Open DevTools â†’ Network tab â†’ use the AI assistant â†’ look for `leaves.mintlify.com/api/assistant/{project-id}/message`

## Configuration

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `OPENAI_API_KEY` | â€” | Required for local RAG mode |
| `DOCMOLE_DATA_DIR` | `~/.docmole` | Data directory for projects |

### Project structure

```
~/.docmole/
â”œâ”€â”€ projects/
â”‚   â””â”€â”€ <project-id>/
â”‚       â”œâ”€â”€ config.yaml      # Project configuration
â”‚       â””â”€â”€ lancedb/         # Vector database
â””â”€â”€ global.yaml              # Global settings
```

## Documentation

See [AGENT.md](./AGENT.md) for detailed documentation including:
- Architecture details
- Backend implementations
- Enterprise deployment guides

## Contributing

PRs welcome! See the [contributing guide](./CONTRIBUTING.md) for details.

## Acknowledgments

- [Mintlify](https://mintlify.com) for amazing documentation tooling
- [Anthropic](https://anthropic.com) for Claude and the MCP protocol
- [LanceDB](https://lancedb.com) for the vector database

## License

The Docmole codebase is under [MIT license](./LICENSE).
